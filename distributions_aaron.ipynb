{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from fitter import Fitter\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from scipy import stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_non_visible(s):\n",
    "    \"\"\"Strip if s is a string, otherwise return s.\"\"\"\n",
    "    if isinstance(s, str):\n",
    "        return s.strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def read_data(file):\n",
    "    \"\"\"Reads the first 4 columns from the given file and drops empty rows.\"\"\"\n",
    "    data = pd.read_csv(\n",
    "        file, delimiter=\",\", usecols=[0, 1, 2, 3], parse_dates=[[0, 1]]\n",
    "    )\n",
    "    data.columns = [\"date\", \"m\", \"v\"]\n",
    "    data = data[data[\"date\"] != \"nan nan\"]\n",
    "    data = data.dropna(how=\"all\")\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "    data = data.applymap(trim_non_visible)\n",
    "    return data.sort_values(by=[\"date\"])\n",
    "\n",
    "\n",
    "def _get_time_differences(df):\n",
    "    \"\"\"Returns the time differences between rocks in hours.\"\"\"\n",
    "    return df[\"date\"].diff().dt.total_seconds() / 3600\n",
    "\n",
    "\n",
    "def add_time_differences(df):\n",
    "    \"\"\"Adds the time differences to the dataframe.\"\"\"\n",
    "    df[\"time_differences\"] = _get_time_differences(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_energy(df):\n",
    "    \"\"\"Adds the energy to the dataframe.\"\"\"\n",
    "    df[\"e\"] = 0.5 * df[\"m\"] * df[\"v\"] ** 2\n",
    "    return df\n",
    "\n",
    "\n",
    "def reorder_columns(df):\n",
    "    \"\"\"Reorders the columns of the dataframe.\"\"\"\n",
    "    cols = [\"zone\", \"date\", \"time_differences\", \"m\", \"v\", \"e\"]\n",
    "    existing_columns = [col for col in cols if col in df.columns]\n",
    "    return df[existing_columns]\n",
    "\n",
    "\n",
    "def scatter_plot(\n",
    "    df: pd.DataFrame,\n",
    "    col: str,\n",
    "    c=\"zone\",\n",
    "    colorbar=False,\n",
    "    colormap=\"viridis\",\n",
    "    title=None,\n",
    "):\n",
    "    \"\"\"Plots the given column of the given data frame as a scatter plot.\"\"\"\n",
    "    if title is None:\n",
    "        title = f\"{col.upper()} vs. Date\"\n",
    "    title = title + f\"\\nnumber of records: {len(df)}\"\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    ax = df.plot.scatter(\n",
    "        x=\"date\", y=col, c=c, colorbar=colorbar, colormap=colormap\n",
    "    )\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "    ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    plt.title(\n",
    "        f\"{col} vs. date\\nnumber of records: {len(df)}\"\n",
    "        if title is None\n",
    "        else title\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "def plot_histogram(df: pd.DataFrame, col: str, zone: int, title: str = None):\n",
    "    \"\"\"Plots the given column of the given dataframe as a histogram.\"\"\"\n",
    "    if title is None:\n",
    "        title = f\"{col.upper()} for Zone {zone}\"\n",
    "    title = title + f\"\\nnumber of records: {len(df)}\"\n",
    "    df[col].hist(bins=np.sqrt(len(df[col])).astype(int) * 6)\n",
    "    plt.xlabel(col.upper())\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def fit(values, distributions=None):\n",
    "    \"\"\"Fit distributions to the values and return the best fit.\"\"\"\n",
    "    if distributions is None:\n",
    "        distributions = [\n",
    "            stats.norm,\n",
    "            stats.expon,\n",
    "            stats.uniform,\n",
    "            stats.gamma,\n",
    "            stats.lognorm,\n",
    "            stats.pareto,\n",
    "            stats.weibull_min,\n",
    "            stats.weibull_max,\n",
    "        ]\n",
    "    results = []\n",
    "\n",
    "    for distribution in distributions:\n",
    "        # Get parameters of the distribution (MLE)\n",
    "        params = distribution.fit(values)\n",
    "\n",
    "        # Compute the Kolmogorov-Smirnov test to assess the goodness of fit.\n",
    "        _, p = stats.kstest(values, distribution.name, args=params)\n",
    "\n",
    "        # Append results\n",
    "        results.append((distribution, p, params))\n",
    "\n",
    "    # Sort results by p-values (higher is better)\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_qq(values, fit_results, zone, col, num=5):\n",
    "    \"\"\"Plot Q-Q plot for the best fitting distributions.\"\"\"\n",
    "    for distribution, _, params in fit_results[:num]:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        stats.probplot(values, dist=distribution, sparams=params, plot=plt)\n",
    "        plt.title(\n",
    "            f\"Q-Q Plot for {distribution.name} distribution vs {col.upper()} in zone {zone}\"\n",
    "        )\n",
    "        plt.axis(\"equal\")\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = read_data(\"data/out_1.csv\")\n",
    "data_1[\"zone\"] = 1\n",
    "data_2 = read_data(\"data/out_2.csv\")\n",
    "data_2[\"zone\"] = 2\n",
    "# join the two dataframes and sort by date\n",
    "df = pd.concat([data_1, data_2]).sort_values(by=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the data\n",
    "print(df.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAs, Zeros and Empty Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count = df.isna().sum()\n",
    "zero_count = (df == 0).sum()\n",
    "empty_string_count = (df == \"\").sum()\n",
    "\n",
    "print(\"Number of NAs in each column:\")\n",
    "print(na_count)\n",
    "print(\"\\nNumber of zeros in each column:\")\n",
    "print(zero_count)\n",
    "print(\"\\nNumber of empty strings in each column:\")\n",
    "print(empty_string_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize column 'm' for each zone\n",
    "print(\"\\n\", df.groupby(\"zone\")[\"m\"].describe())\n",
    "\n",
    "# replace zeros with median of the same zone\n",
    "df[\"m\"] = df.groupby(\"zone\")[\"m\"].transform(lambda x: x.replace(0, x.median()))\n",
    "\n",
    "# summarize column 'm' for each zone\n",
    "print(\"\\n\", df.groupby(\"zone\")[\"m\"].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Time Differences and Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T12:52:24.250343Z",
     "start_time": "2023-04-21T12:52:24.205904Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add time differences and energy to the dataframes and reorder the columns.\n",
    "# Also convert the zone column to a categorical variable.\n",
    "# This is done so that the zone column is not used as a numerical variable.\n",
    "df = reorder_columns(add_energy(add_time_differences(df)))\n",
    "df[\"zone\"] = df[\"zone\"].astype(\"category\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the zones into seperate files, so they can be compared to the original files.\n",
    "df.to_csv(\"data/data.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T12:52:25.503320Z",
     "start_time": "2023-04-21T12:52:24.698791Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in [\"m\", \"v\", \"e\"]:\n",
    "    scatter_plot(df, col)\n",
    "scatter_plot(df, \"e\", c=\"m\", colorbar=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T09:31:40.539939Z",
     "start_time": "2023-04-21T09:31:39.610131Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in [\"time_differences\", \"m\", \"v\", \"e\"]:\n",
    "    for zone in [1, 2]:\n",
    "        plot_histogram(df[df[\"zone\"] == zone], col, zone)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T16:20:30.266989Z",
     "start_time": "2023-04-20T16:20:03.291171Z"
    },
    "collapsed": false
   },
   "source": [
    "# Fit Distributions\n",
    "\n",
    "MLE has been used to fit parameters and the Kolmogorov-Smirnov test has been used to determine goodness of fit as p value. Good strategy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"time_differences\", \"m\", \"v\", \"e\"]:\n",
    "    for zone in [1, 2]:\n",
    "        values = df[df[\"zone\"] == zone][col].dropna()\n",
    "        f = fit(values)\n",
    "        print(f\"Zone {zone}, column {col}\")\n",
    "        for distribution, p, params in f[:5]:\n",
    "            print(f\"{distribution.name}\\n\\tp: {p}\\n\\tparams: {params}\")\n",
    "        plot_qq(values, f, zone, col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
